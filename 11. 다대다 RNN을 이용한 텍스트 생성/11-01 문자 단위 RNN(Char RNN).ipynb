{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('mps:0' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 훈련 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자 집합의 크기 : 5\n"
     ]
    }
   ],
   "source": [
    "input_str = 'apple'\n",
    "label_str = 'pple!'\n",
    "char_vocab = sorted(list(set(input_str+label_str)))\n",
    "vocab_size = len(char_vocab)\n",
    "print(f\"문자 집합의 크기 : {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = vocab_size\n",
    "hidden_size = 5\n",
    "output_size = 5\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!': 0, 'a': 1, 'e': 2, 'l': 3, 'p': 4}\n"
     ]
    }
   ],
   "source": [
    "char_to_index = dict((c, i) for i, c in enumerate(char_vocab))\n",
    "print(char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '!', 1: 'a', 2: 'e', 3: 'l', 4: 'p'}\n"
     ]
    }
   ],
   "source": [
    "index_to_char = {}\n",
    "for key, value in char_to_index.items():\n",
    "    index_to_char[value] = key\n",
    "print(index_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 4, 3, 2]\n",
      "[4, 4, 3, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "x_data = [char_to_index[c] for c in input_str]\n",
    "y_data = [char_to_index[c] for c in label_str]\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [x_data]\n",
    "y_data = [y_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0.]])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_one_hot = [np.eye(vocab_size)[x] for x in x_data]\n",
    "x_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f4/tmy3_62j52n251v90rm6sc700000gn/T/ipykernel_98398/3126415423.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:248.)\n",
      "  X = torch.FloatTensor(x_one_hot)\n",
      "/var/folders/f4/tmy3_62j52n251v90rm6sc700000gn/T/ipykernel_98398/3126415423.py:2: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  Y = torch.LongStorage(y_data)\n"
     ]
    }
   ],
   "source": [
    "X = torch.FloatTensor(x_one_hot)\n",
    "Y = torch.LongStorage(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.rnn = torch.nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_size, output_size, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _status = self.rnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = net(X)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.view(-1, input_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'torch.storage.TypedStorage' object has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/yejin/Yejin_drive/VSC_projects/start-pytorch/11. 다대다 RNN을 이용한 텍스트 생성/11-01 문자 단위 RNN(Char RNN).ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yejin/Yejin_drive/VSC_projects/start-pytorch/11.%20%EB%8B%A4%EB%8C%80%EB%8B%A4%20RNN%EC%9D%84%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EC%83%9D%EC%84%B1/11-01%20%EB%AC%B8%EC%9E%90%20%EB%8B%A8%EC%9C%84%20RNN%28Char%20RNN%29.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yejin/Yejin_drive/VSC_projects/start-pytorch/11.%20%EB%8B%A4%EB%8C%80%EB%8B%A4%20RNN%EC%9D%84%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EC%83%9D%EC%84%B1/11-01%20%EB%AC%B8%EC%9E%90%20%EB%8B%A8%EC%9C%84%20RNN%28Char%20RNN%29.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m outputs \u001b[39m=\u001b[39m net(X)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yejin/Yejin_drive/VSC_projects/start-pytorch/11.%20%EB%8B%A4%EB%8C%80%EB%8B%A4%20RNN%EC%9D%84%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EC%83%9D%EC%84%B1/11-01%20%EB%AC%B8%EC%9E%90%20%EB%8B%A8%EC%9C%84%20RNN%28Char%20RNN%29.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, input_size), Y\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)) \u001b[39m# view를 하는 이유는 Batch 차원 제거를 위해\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yejin/Yejin_drive/VSC_projects/start-pytorch/11.%20%EB%8B%A4%EB%8C%80%EB%8B%A4%20RNN%EC%9D%84%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EC%83%9D%EC%84%B1/11-01%20%EB%AC%B8%EC%9E%90%20%EB%8B%A8%EC%9C%84%20RNN%28Char%20RNN%29.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward() \u001b[39m# 기울기 계산\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yejin/Yejin_drive/VSC_projects/start-pytorch/11.%20%EB%8B%A4%EB%8C%80%EB%8B%A4%20RNN%EC%9D%84%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EC%83%9D%EC%84%B1/11-01%20%EB%AC%B8%EC%9E%90%20%EB%8B%A8%EC%9C%84%20RNN%28Char%20RNN%29.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep() \u001b[39m# 아까 optimizer 선언 시 넣어둔 파라미터 업데이트\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'torch.storage.TypedStorage' object has no attribute 'view'"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(X)\n",
    "    loss = criterion(outputs.view(-1, input_size), Y.view(-1)) # view를 하는 이유는 Batch 차원 제거를 위해\n",
    "    loss.backward() # 기울기 계산\n",
    "    optimizer.step() # 아까 optimizer 선언 시 넣어둔 파라미터 업데이트\n",
    "\n",
    "    # 아래 세 줄은 모델이 실제 어떻게 예측했는지를 확인하기 위한 코드.\n",
    "    result = outputs.data.numpy().argmax(axis=2) # 최종 예측값인 각 time-step 별 5차원 벡터에 대해서 가장 높은 값의 인덱스를 선택\n",
    "    result_str = ''.join([index_to_char[c] for c in np.squeeze(result)])\n",
    "    print(i, \"loss: \", loss.item(), \"prediction: \", result, \"true Y: \", y_data, \"prediction str: \", result_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
