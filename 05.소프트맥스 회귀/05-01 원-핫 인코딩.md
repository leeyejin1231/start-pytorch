## 원-핫 인코딩

### 1. 원-핫 인코딩

one-hot vector

### 2. 원-핫 벡터의 무작위성

정수 인코딩과 달리 원-핫 인코딩은 분류 문제 모든 클래스 간의 관계를 균등하게 분배한다. (유클리드 거리 동일)

-   단어의 유사성을 구할 수는 없음

## 소프트맥스 회귀 이해하기

### 1. 다중 클래스 분류

#### 1. Logistic regression

![Alt text](image.png)  
시그모이드, 이중분류

#### 2. Softmax regression

![Alt text](image-1.png)  
확률의 합은 1  
$$H(X)=softmax(WX+B)$$

### 2. 소프트맥스 함수

![Alt text](image-2.png)    
i번 째 클래스가 정답일 확률

![Alt text](image-4.png)  

![Alt text](image-5.png)  
c = 클래스 개수

### 3. 붓꽃 품종 푼류하기 행렬 연산으로 이해하기

![Alt text](image-6.png)  

### 4. Loss function

#### 1. 크로스 엔트로피

![Alt text](image-7.png)

#### 2. 이진 분류에서의 크로스 엔트로피 함수

![Alt text](image-8.png)  
소프트맥스의 비용함수와 로시스틱 회귀의 비용함수는 같다.
